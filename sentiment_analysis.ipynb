{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary utility libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# nltk for text preprocessing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# sklearn for preprocessing data and for evaluating the metrics\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, log_loss, plot_confusion_matrix\n",
    "\n",
    "# nlpaug for class imbalance handling\n",
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "# keras for neural network\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, Bidirectional, Conv1D, GlobalMaxPool1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the train and test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Polarity\n",
       "0                           Wow... Loved this place.         1\n",
       "1                                 Crust is not good.         0\n",
       "2          Not tasty and the texture was just nasty.         0\n",
       "3  Stopped by during the late May bank holiday of...         1\n",
       "4  The selection on the menu was great and so wer...         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./data/sentiment_train.csv')\n",
    "df_test = pd.read_csv('./data/sentiment_test.csv')\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observing and handling the class imbalance problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1213\n",
      "1    1187\n",
      "Name: Polarity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Plot sentiment distribution\n",
    "df_train['Polarity'].value_counts().plot(kind = 'barh', figsize = (5,2));\n",
    "plt.title('Distribution of polarity in train dataset', fontsize = 10, weight = 'bold')\n",
    "plt.xlabel('Frequency', fontsize = 10)\n",
    "plt.xticks(fontsize = 8)\n",
    "plt.yticks(fontsize = 8)\n",
    "plt.show()\n",
    "\n",
    "print(df_train['Polarity'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe here that the training data is not hugely imbalanced and there is only a slight difference between the number of training instances we have for negative and positive polarity sentences. We can easily mitigate this by using a text augmentation method called backtranslation.\n",
    "\n",
    "The back-translation process works in the following way:\n",
    "* Take some sentence and translate to another language\n",
    "* Translate the output sentence back to original language\n",
    "* Check if the new sentence is different from the original sentence. If it is, then we use this new sentence as an augmented version of the original text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_translation_aug = naw.BackTranslationAug(\n",
    "    from_model_name='facebook/wmt19-en-de', \n",
    "    to_model_name='facebook/wmt19-de-en'\n",
    ")\n",
    "    \n",
    "def generate_augmented_text(text):\n",
    "    augmented_text = back_translation_aug.augment(text)\n",
    "    return augmented_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:  I kept looking at the time and it had soon become 35 minutes, yet still no food.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bikram/anaconda3/envs/alt/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented Text:  I looked at the time again and again and soon it was 35 minutes, but still no food.\n"
     ]
    }
   ],
   "source": [
    "# Example of text augmentation:\n",
    "\n",
    "text = df_train['Sentence'][979]\n",
    "print(\"Original Text: \", text)\n",
    "print()\n",
    "print(\"Augmented Text: \", generate_augmented_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 28/378 [00:34<07:14,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "long_pos_texts = df_train[(df_train['Polarity'] == 1) & \n",
    "                          (df_train['Sentence'].str.len() >= 70)]['Sentence'].values\n",
    "\n",
    "count = 0\n",
    "for text in tqdm(long_pos_texts):\n",
    "    new_text = generate_augmented_text(text)\n",
    "    if new_text != text:\n",
    "        count += 1\n",
    "        df_train = df_train.append({\"Sentence\": new_text, \"Polarity\": 1}, ignore_index=True)\n",
    "        if count == 26:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1213\n",
      "0    1213\n",
      "Name: Polarity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Plot sentiment distribution\n",
    "df_train['Polarity'].value_counts().plot(kind = 'barh', figsize = (5,2));\n",
    "plt.title('Distribution of polarity in train dataset', fontsize = 10, weight = 'bold')\n",
    "plt.xlabel('Frequency', fontsize = 10)\n",
    "plt.xticks(fontsize = 8)\n",
    "plt.yticks(fontsize = 8)\n",
    "plt.show()\n",
    "\n",
    "print(df_train['Polarity'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that the data is perfectly balanced now and we have equal number of both positive and negative polarity examples. We can proceed ahead now with preprocessing and training our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing and vectorizing the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 85 # Maximum length of sentence the model will handle\n",
    "DEFAULT_BATCH_SIZE = 128 # Size of number of instances in a batch the model will take while training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important that we clean and preprocess the text a bit before we can use it for training purposes. So, for text cleaning purpose, we will perform the following steps:\n",
    "\n",
    "\n",
    "* Contraction check: check if there’s any contracted form, and replace it with its original form\n",
    "* Parsing: done with Spacy\n",
    "* Filtering punctuation, white space while keeping the text content intact\n",
    "* Lemmatized the words in the text. Lemmatization is basically the process of grouping together the different inflected forms of a word so they can be analyzed as a single item. (eg. going will be lemmatized to go)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTRACTION_MAPPING = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"cant\": \"cannot\",\n",
    "                   \"can't've\": \"cannot have\", \"'cause\": \"because\", \"could've\": \"could have\", \n",
    "                   \"couldn't\": \"could not\", \"couldn't've\": \"could not have\",\"didn't\": \"did not\", \n",
    "                   \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \n",
    "                   \"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n",
    "                   \"he'd\": \"he would\", \"he'd've\": \"he would have\", \"he'll\": \"he will\", \n",
    "                   \"he'll've\": \"he will have\", \"he's\": \"he is\", \"how'd\": \"how did\", \n",
    "                   \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \n",
    "                   \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \n",
    "                   \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \n",
    "                   \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\", \n",
    "                   \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \n",
    "                   \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \n",
    "                   \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \n",
    "                   \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \n",
    "                   \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \n",
    "                   \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \n",
    "                   \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \n",
    "                   \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
    "                   \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \n",
    "                   \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \n",
    "                   \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \n",
    "                   \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \n",
    "                   \"this's\": \"this is\",\n",
    "                   \"that'd\": \"that would\", \"that'd've\": \"that would have\",\"that's\": \"that is\", \n",
    "                   \"there'd\": \"there would\", \"there'd've\": \"there would have\",\"there's\": \"there is\", \n",
    "                       \"here's\": \"here is\",\n",
    "                   \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \n",
    "                   \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \n",
    "                   \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \n",
    "                   \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \n",
    "                   \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \n",
    "                   \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \n",
    "                   \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \n",
    "                   \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \n",
    "                   \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \n",
    "                   \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \n",
    "                   \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \n",
    "                   \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \n",
    "                   \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                   \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                   \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \n",
    "                   \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text, mapping):\n",
    "    replace_white_space = [\"\\n\"]\n",
    "    for s in replace_white_space:\n",
    "        text = text.replace(s, \" \")\n",
    "    replace_punctuation = [\"’\", \"‘\", \"´\", \"`\", \"\\'\", r\"\\'\"]\n",
    "    for s in replace_punctuation:\n",
    "        text = text.replace(s, \"'\")\n",
    "    \n",
    "    mapped_string = []\n",
    "    for t in text.split(\" \"):\n",
    "        if t in mapping:\n",
    "            mapped_string.append(mapping[t])\n",
    "        elif t.lower() in mapping:\n",
    "            mapped_string.append(mapping[t.lower()])\n",
    "        else:\n",
    "            mapped_string.append(lemmatizer.lemmatize(t))\n",
    "    return ' '.join(mapped_string)\n",
    "\n",
    "X_train = [clean_text(text, CONTRACTION_MAPPING) for text in df_train['Sentence'].values]\n",
    "X_test = [clean_text(text, CONTRACTION_MAPPING) for text in df_test['Sentence'].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we tokenize each of the preprocessed texts, which involves converting each sequence into an integer encoded represenation and normalizing the length of the sequences (by using padding). Please note very little pre-processing was done to the text. More specifically there's no stemming or POS tagging, common in NLP tasks. Additionally, text is left in original case (i.e not cast to lowercase). The data already is pretty clean to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens: 4493\n",
      "Max Token Index: 4493 \n",
      "\n",
      "Sample Text Before Processing: Though The Wind and the Lion is told largely through the eyes of the son, every member of the family can identify with one of the characters, whether it be Sean Connery's noble brigand, Candace Bergen's feisty heroine, John Huston's wily John Hay or Steve Kanaly's spiffy, radiant, ruthless can-do lieutenant, Roosevelt's \"Big Stick\".  \n",
      "Sample Text After Processing: [\"Though The Wind and the Lion is told largely through the eye of the son every member of the family can identify with one of the characters whether it be Sean Connery's noble brigand Candace Bergen's feisty heroine John Huston's wily John Hay or Steve Kanaly's spiffy radiant ruthless can do lieutenant Roosevelt's Big Stick\"] \n",
      "\n",
      "What the model will interpret: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4431, 11, 1195, 2, 1, 1196, 5, 523, 1270, 481, 1, 793, 10, 1, 766, 146, 4432, 10, 1, 277, 82, 4433, 15, 41, 10, 1, 736, 547, 7, 30, 4434, 4435, 4436, 4437, 4438, 4439, 4440, 4441, 910, 4442, 4443, 910, 4444, 58, 915, 4445, 4446, 4447, 4448, 82, 38, 4449, 4450, 709, 4451]\n"
     ]
    }
   ],
   "source": [
    "# tokenize the sentences\n",
    "tokenizer = Tokenizer(lower=False)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# pad the sequences\n",
    "X_train = pad_sequences(X_train, maxlen=MAX_SEQ_LEN)\n",
    "X_test = pad_sequences(X_test, maxlen=MAX_SEQ_LEN)\n",
    "\n",
    "print('Number of Tokens:', len(tokenizer.word_index))\n",
    "print(\"Max Token Index:\", X_train.max(), \"\\n\")\n",
    "\n",
    "print('Sample Text Before Processing:', df_train['Sentence'].values[2390])\n",
    "print('Sample Text After Processing:', tokenizer.sequences_to_texts([X_train[2390]]), '\\n')\n",
    "\n",
    "print('What the model will interpret:', X_train[2390].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will prepare the output data as well. In this case the sentiment is classified as Negative or Positive. To make it suitable for a deep learning model each sentiment will be converted to a vector of length 2, where each position corresponds to a sentiment class: Negative = 0 and Positive = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encode Y values:\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "y_train = encoder.fit_transform(df_train['Polarity'].values)\n",
    "y_train = to_categorical(y_train) \n",
    "\n",
    "y_test = encoder.fit_transform(df_test['Polarity'].values)\n",
    "y_test = to_categorical(y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading glove embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily access pre-trained word vectors for training purposes in NLP that are trained against billions of documents. These are generally recommended for NLP tasks as they provide a substantial increase in performance over embeddings trained on the fly.\n",
    "\n",
    "This is a form of Transfer Learning where existing model weights are re-purposed for a new task (this much more prevalent amongst Image Classification tasks).\n",
    "We'll use the GloVe Embeddings, which are trained on several different text sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "def get_embdedings_matrix(embeddings_index, word_index, nb_words = None):\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    print('Shape of Full Embeddding Matrix', all_embs.shape)\n",
    "    embed_dims = all_embs.shape[1]\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "\n",
    "    #best to free up memory, given the size, which is usually ~3-4GB in memory\n",
    "    del all_embs\n",
    "    if nb_words is None:\n",
    "        nb_words = len(word_index)\n",
    "    else:\n",
    "        nb_words = min(nb_words, len(word_index))\n",
    "    \n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words+1, embed_dims))\n",
    "    found_vectors = 0\n",
    "    words_not_found = []\n",
    "    for word, i in tqdm(word_index.items()):\n",
    "        if i >= nb_words: \n",
    "            continue\n",
    "        embedding_vector = None\n",
    "        if word in embeddings_index:\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "        elif word.lower() in embeddings_index:\n",
    "            embedding_vector = embeddings_index.get(word.lower())\n",
    "        elif '#'+word.lower() in embeddings_index:\n",
    "            embedding_vector = embeddings_index.get('#'+word.lower())\n",
    "            \n",
    "        if embedding_vector is not None: \n",
    "            found_vectors += 1\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            words_not_found.append((word, i))\n",
    "\n",
    "    print(\"% of Vectors found in Corpus\", found_vectors / nb_words)\n",
    "    return embedding_matrix, words_not_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:25, 15653.37it/s]\n",
      "/home/bikram/anaconda3/envs/alt/lib/python3.7/site-packages/ipykernel_launcher.py:9: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built Embedding Index: 400000\n",
      "Shape of Full Embeddding Matrix (400000, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4493/4493 [00:00<00:00, 425981.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of Vectors found in Corpus 0.9561540173603383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def load_emb_matrix(word_index):\n",
    "    embed_file_path = './glove.6B.300d.txt'\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in tqdm(open(embed_file_path)))\n",
    "    print(\"Built Embedding Index:\", len(embeddings_index))\n",
    "    return get_embdedings_matrix(embeddings_index, word_index)\n",
    "\n",
    "print('Loading Glove Model...')\n",
    "\n",
    "emb_matrix, words_not_found = load_emb_matrix(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the keras model and performing parameter tuning with cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural nets we'll be using is based on Recurrent Neural Network(RNN) Architecture.\n",
    "\n",
    "An RNN is a specific type of Deep Learning Architecture that's specially adapted to handle time dependent information such as human language (e.g. Text, Audio), signal outputs from an IoT Device, or any other Time Series based data(stock prices, though not recommeneded). An LSTM is a specific type of RNN and is used in a lot of commercial applications(Siri), also consider GRU's, which can occasionally outperform LSTMs on certain tasks and ther are more advanced models as well (like Attention, BERT, 1D Convolutions, Capsules, etc)\n",
    "\n",
    "In our neural network model we use the following layers:\n",
    "\n",
    "* Embedding - Matrix of Word Vectors, where each vector store the \"meaning\" of the word. These can be trained on the fly or you can leverage existing pre-trained vector.\n",
    "\n",
    "* LSTM - Recurrent Neural Network that allows for the \"building\" of state over time\n",
    "\n",
    "* Dense - Feed Forward Neural Net used to interpret the LSTM Output\n",
    "\n",
    "* Bi-Directional LSTM - As the name suggest this Layer \"reads\" text both forwards and backwards and allows the model to get information from past and future states simultaneously. It also usually provides a nice boost in performance over the single pass LSTM.\n",
    "\n",
    "* Dropout - It is added to reduce overfitting, as the number of paramters in the model increases. A Dropout Layer, drops data from the input, but only during training, which encourages the model to be more \"robust\" and not become overly dependent on specific signals from the training data to make predictions. Since we have a relatively small data-set compared to our model size, drop-out is critical to ensure the model doesnt just quickly overfit the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(embed_matrix=emb_matrix, optimizer='adam', spatial_dropout=0.3, lstm_dropout=0.25, lstm_units=128):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim = embed_matrix.shape[0], output_dim=embed_matrix.shape[1], \n",
    "                        input_length=MAX_SEQ_LEN, weights=[embed_matrix], trainable=False))\n",
    "    model.add(SpatialDropout1D(spatial_dropout))\n",
    "    model.add(Bidirectional(LSTM(lstm_units, dropout=lstm_dropout, recurrent_dropout=lstm_dropout, return_sequences=True)))\n",
    "    model.add(Conv1D(64, 4))\n",
    "    model.add(GlobalMaxPool1D())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    print(model.summary())\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Deep Neural Network that can generalize well to new data is a very challenging problem. Furthermore, Deep learning models are full of hyper-parameters and finding the optimal ones can be a tedious process. To solve this, we can use parameter tuning methods like gridsearch or randomized search. Sklearn already provides these implementations. We will be going ahead with Randomized Search as it takes less time as compared to Grid Search with minimal affect on the results. By defining the search parameters, we provide the hyperparameter tuning tool to choose the best possible combinations among them to build a highly generalized deep learning model that can work on any unseen data in future. Additionally, randomized search can perform cross validation splits in order to determine the best parameters. This is a great method when we have limited amount of data to train our model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_estimator = KerasClassifier(build_fn=build_model, verbose=1)\n",
    "\n",
    "# define the randomized search parameters\n",
    "param_grid = {\n",
    "    'epochs': [25, 30, 35],\n",
    "    'optimizer':['RMSprop', 'adam'],\n",
    "    'spatial_dropout': [0.2, 0.3, 0.4],\n",
    "    'lstm_dropout': [0.20, 0.25, 0.30],\n",
    "    'lstm_units': [64, 128, 256],\n",
    "    'batch_size':[32, 64, 128],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best: 0.871615 using {'spatial_dropout': 0.4, 'optimizer': 'adam', 'lstm_units': 128, 'lstm_dropout': 0.3, 'epochs': 35, 'batch_size': 64}\n",
      "0.865742 (0.038547) with: {'spatial_dropout': 0.2, 'optimizer': 'RMSprop', 'lstm_units': 128, 'lstm_dropout': 0.2, 'epochs': 30, 'batch_size': 64}\n",
      "0.871182 (0.021168) with: {'spatial_dropout': 0.3, 'optimizer': 'RMSprop', 'lstm_units': 256, 'lstm_dropout': 0.3, 'epochs': 35, 'batch_size': 128}\n",
      "0.866133 (0.033684) with: {'spatial_dropout': 0.2, 'optimizer': 'adam', 'lstm_units': 128, 'lstm_dropout': 0.2, 'epochs': 25, 'batch_size': 32}\n",
      "0.853086 (0.037047) with: {'spatial_dropout': 0.3, 'optimizer': 'adam', 'lstm_units': 128, 'lstm_dropout': 0.2, 'epochs': 25, 'batch_size': 128}\n",
      "0.852464 (0.050919) with: {'spatial_dropout': 0.2, 'optimizer': 'RMSprop', 'lstm_units': 128, 'lstm_dropout': 0.25, 'epochs': 25, 'batch_size': 64}\n",
      "0.858274 (0.033303) with: {'spatial_dropout': 0.4, 'optimizer': 'adam', 'lstm_units': 64, 'lstm_dropout': 0.3, 'epochs': 25, 'batch_size': 64}\n",
      "0.864024 (0.027941) with: {'spatial_dropout': 0.4, 'optimizer': 'adam', 'lstm_units': 64, 'lstm_dropout': 0.2, 'epochs': 25, 'batch_size': 128}\n",
      "0.871615 (0.037675) with: {'spatial_dropout': 0.4, 'optimizer': 'adam', 'lstm_units': 128, 'lstm_dropout': 0.3, 'epochs': 35, 'batch_size': 64}\n",
      "0.863668 (0.033221) with: {'spatial_dropout': 0.2, 'optimizer': 'RMSprop', 'lstm_units': 128, 'lstm_dropout': 0.25, 'epochs': 35, 'batch_size': 64}\n",
      "0.866015 (0.030406) with: {'spatial_dropout': 0.2, 'optimizer': 'adam', 'lstm_units': 128, 'lstm_dropout': 0.2, 'epochs': 30, 'batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "kfold_splits = 5\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=keras_estimator,  \n",
    "                          n_jobs=-1, \n",
    "                          verbose=2,\n",
    "                          refit=False,\n",
    "                          scoring='f1',\n",
    "                          cv=kfold_splits,\n",
    "                          error_score='raise',\n",
    "                          return_train_score=True,\n",
    "                          param_distributions=param_grid)\n",
    "\n",
    "tuning_results = random_search.fit(X_train, np.argmax(y_train, axis=1), ) \n",
    "\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (tuning_results.best_score_, tuning_results.best_params_))\n",
    "means = tuning_results.cv_results_['mean_test_score']\n",
    "stds = tuning_results.cv_results_['std_test_score']\n",
    "params = tuning_results.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spatial_dropout': 0.4,\n",
       " 'optimizer': 'adam',\n",
       " 'lstm_units': 128,\n",
       " 'lstm_dropout': 0.3,\n",
       " 'epochs': 35,\n",
       " 'batch_size': 64}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_results.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the final model with the best parameters and testing the model on unseen test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through hyperparameter optimization, we have got the best parameters to train our model on. So we will select the best parameters as given by Randomized Search and train our model using all of the data in the train set. After training the model, we can check the model's performance as to how well it generalizes by generating metrics on unseen test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 85, 300)           1348200   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_5 (Spatial (None, 85, 300)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 85, 256)           439296    \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 82, 64)            65600     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 1,857,386\n",
      "Trainable params: 509,186\n",
      "Non-trainable params: 1,348,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/35\n",
      "38/38 - 9s - loss: 0.6729 - accuracy: 0.5882\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.67291, saving model to model.hdf5\n",
      "Epoch 2/35\n",
      "38/38 - 5s - loss: 0.5108 - accuracy: 0.7498\n",
      "\n",
      "Epoch 00002: loss improved from 0.67291 to 0.51083, saving model to model.hdf5\n",
      "Epoch 3/35\n",
      "38/38 - 5s - loss: 0.4552 - accuracy: 0.7931\n",
      "\n",
      "Epoch 00003: loss improved from 0.51083 to 0.45525, saving model to model.hdf5\n",
      "Epoch 4/35\n",
      "38/38 - 5s - loss: 0.4234 - accuracy: 0.7984\n",
      "\n",
      "Epoch 00004: loss improved from 0.45525 to 0.42345, saving model to model.hdf5\n",
      "Epoch 5/35\n",
      "38/38 - 5s - loss: 0.3794 - accuracy: 0.8318\n",
      "\n",
      "Epoch 00005: loss improved from 0.42345 to 0.37941, saving model to model.hdf5\n",
      "Epoch 6/35\n",
      "38/38 - 5s - loss: 0.3651 - accuracy: 0.8388\n",
      "\n",
      "Epoch 00006: loss improved from 0.37941 to 0.36511, saving model to model.hdf5\n",
      "Epoch 7/35\n",
      "38/38 - 5s - loss: 0.3227 - accuracy: 0.8557\n",
      "\n",
      "Epoch 00007: loss improved from 0.36511 to 0.32271, saving model to model.hdf5\n",
      "Epoch 8/35\n",
      "38/38 - 5s - loss: 0.3062 - accuracy: 0.8689\n",
      "\n",
      "Epoch 00008: loss improved from 0.32271 to 0.30619, saving model to model.hdf5\n",
      "Epoch 9/35\n",
      "38/38 - 5s - loss: 0.3016 - accuracy: 0.8669\n",
      "\n",
      "Epoch 00009: loss improved from 0.30619 to 0.30164, saving model to model.hdf5\n",
      "Epoch 10/35\n",
      "38/38 - 5s - loss: 0.2584 - accuracy: 0.8883\n",
      "\n",
      "Epoch 00010: loss improved from 0.30164 to 0.25843, saving model to model.hdf5\n",
      "Epoch 11/35\n",
      "38/38 - 5s - loss: 0.2524 - accuracy: 0.8974\n",
      "\n",
      "Epoch 00011: loss improved from 0.25843 to 0.25242, saving model to model.hdf5\n",
      "Epoch 12/35\n",
      "38/38 - 5s - loss: 0.2239 - accuracy: 0.9027\n",
      "\n",
      "Epoch 00012: loss improved from 0.25242 to 0.22389, saving model to model.hdf5\n",
      "Epoch 13/35\n",
      "38/38 - 5s - loss: 0.2202 - accuracy: 0.9011\n",
      "\n",
      "Epoch 00013: loss improved from 0.22389 to 0.22023, saving model to model.hdf5\n",
      "Epoch 14/35\n",
      "38/38 - 5s - loss: 0.2011 - accuracy: 0.9097\n",
      "\n",
      "Epoch 00014: loss improved from 0.22023 to 0.20110, saving model to model.hdf5\n",
      "Epoch 15/35\n",
      "38/38 - 5s - loss: 0.1764 - accuracy: 0.9336\n",
      "\n",
      "Epoch 00015: loss improved from 0.20110 to 0.17643, saving model to model.hdf5\n",
      "Epoch 16/35\n",
      "38/38 - 5s - loss: 0.1687 - accuracy: 0.9308\n",
      "\n",
      "Epoch 00016: loss improved from 0.17643 to 0.16866, saving model to model.hdf5\n",
      "Epoch 17/35\n",
      "38/38 - 5s - loss: 0.1596 - accuracy: 0.9283\n",
      "\n",
      "Epoch 00017: loss improved from 0.16866 to 0.15958, saving model to model.hdf5\n",
      "Epoch 18/35\n",
      "38/38 - 5s - loss: 0.1512 - accuracy: 0.9386\n",
      "\n",
      "Epoch 00018: loss improved from 0.15958 to 0.15119, saving model to model.hdf5\n",
      "Epoch 19/35\n",
      "38/38 - 5s - loss: 0.1318 - accuracy: 0.9472\n",
      "\n",
      "Epoch 00019: loss improved from 0.15119 to 0.13180, saving model to model.hdf5\n",
      "Epoch 20/35\n",
      "38/38 - 5s - loss: 0.1257 - accuracy: 0.9563\n",
      "\n",
      "Epoch 00020: loss improved from 0.13180 to 0.12567, saving model to model.hdf5\n",
      "Epoch 21/35\n",
      "38/38 - 5s - loss: 0.1149 - accuracy: 0.9551\n",
      "\n",
      "Epoch 00021: loss improved from 0.12567 to 0.11490, saving model to model.hdf5\n",
      "Epoch 22/35\n",
      "38/38 - 5s - loss: 0.0860 - accuracy: 0.9670\n",
      "\n",
      "Epoch 00022: loss improved from 0.11490 to 0.08597, saving model to model.hdf5\n",
      "Epoch 23/35\n",
      "38/38 - 5s - loss: 0.0885 - accuracy: 0.9703\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.08597\n",
      "Epoch 24/35\n",
      "38/38 - 5s - loss: 0.0790 - accuracy: 0.9728\n",
      "\n",
      "Epoch 00024: loss improved from 0.08597 to 0.07898, saving model to model.hdf5\n",
      "Epoch 25/35\n",
      "38/38 - 5s - loss: 0.0815 - accuracy: 0.9662\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.07898\n",
      "Epoch 26/35\n",
      "38/38 - 5s - loss: 0.0731 - accuracy: 0.9695\n",
      "\n",
      "Epoch 00026: loss improved from 0.07898 to 0.07314, saving model to model.hdf5\n",
      "Epoch 27/35\n",
      "38/38 - 5s - loss: 0.0809 - accuracy: 0.9695\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.07314\n",
      "Epoch 28/35\n",
      "38/38 - 5s - loss: 0.0569 - accuracy: 0.9798\n",
      "\n",
      "Epoch 00028: loss improved from 0.07314 to 0.05690, saving model to model.hdf5\n",
      "Epoch 29/35\n",
      "38/38 - 5s - loss: 0.0575 - accuracy: 0.9782\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.05690\n",
      "Epoch 30/35\n",
      "38/38 - 5s - loss: 0.0611 - accuracy: 0.9753\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.05690\n",
      "Epoch 31/35\n",
      "38/38 - 5s - loss: 0.0532 - accuracy: 0.9810\n",
      "\n",
      "Epoch 00031: loss improved from 0.05690 to 0.05321, saving model to model.hdf5\n",
      "Epoch 32/35\n",
      "38/38 - 5s - loss: 0.0433 - accuracy: 0.9839\n",
      "\n",
      "Epoch 00032: loss improved from 0.05321 to 0.04330, saving model to model.hdf5\n",
      "Epoch 33/35\n",
      "38/38 - 5s - loss: 0.0511 - accuracy: 0.9798\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.04330\n",
      "Epoch 34/35\n",
      "38/38 - 5s - loss: 0.0452 - accuracy: 0.9835\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.04330\n",
      "Epoch 35/35\n",
      "38/38 - 5s - loss: 0.0397 - accuracy: 0.9847\n",
      "\n",
      "Epoch 00035: loss improved from 0.04330 to 0.03973, saving model to model.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f49c8270050>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = build_model(embed_matrix=emb_matrix, optimizer='adam', spatial_dropout=0.4, lstm_dropout=0.3, lstm_units=128)\n",
    "\n",
    "final_model.fit(X_train, y_train, epochs=35, batch_size=64, class_weight=None,\n",
    "                callbacks= [ModelCheckpoint('model.hdf5', monitor='loss', \n",
    "                                            verbose=1, save_best_only=True)], \n",
    "                verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now evaluate the trained model on the unseen test data and see how the model performs on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 16ms/step\n",
      "Test Accuracy 0.8233333333333334\n",
      "F1 Score on Test Set: 0.8233333333333334\n",
      "[[234  53]\n",
      " [ 53 260]]\n"
     ]
    }
   ],
   "source": [
    "final_model = load_model('model.hdf5')\n",
    "predictions = final_model.predict(X_test, verbose=1)\n",
    "\n",
    "print('Test Accuracy', (predictions.argmax(axis = 1) == y_test.argmax(axis = 1)).mean())\n",
    "print('F1 Score on Test Set:', f1_score(y_test.argmax(axis = 1), predictions.argmax(axis = 1), average='weighted'))\n",
    "print(confusion_matrix(y_test.argmax(axis = 1), predictions.argmax(axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Polarity-Actual</th>\n",
       "      <th>Polarity-Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A good commentary of today's love and undoubte...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For people who are first timers in film making...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It was very popular when I was in the cinema, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a feel-good film and that's how I felt wh...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It has northern humour and positive about the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Polarity-Actual  \\\n",
       "0  A good commentary of today's love and undoubte...                1   \n",
       "1  For people who are first timers in film making...                1   \n",
       "2  It was very popular when I was in the cinema, ...                1   \n",
       "3  It's a feel-good film and that's how I felt wh...                1   \n",
       "4  It has northern humour and positive about the ...                1   \n",
       "\n",
       "   Polarity-Predicted  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   1  \n",
       "4                   1  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds = []\n",
    "for idx, (actual, pred) in enumerate(zip(y_test.argmax(axis = 1), predictions.argmax(axis = 1))):\n",
    "    all_preds.append({\"Sentence\" : df_test[\"Sentence\"].iloc[idx],\n",
    "                      \"Polarity-Actual\": actual,\n",
    "                      \"Polarity-Predicted\" : pred})\n",
    "df_preds = pd.DataFrame(all_preds)\n",
    "df_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds.to_csv('./data/sentiment_test_preds.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alt",
   "language": "python",
   "name": "alt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
